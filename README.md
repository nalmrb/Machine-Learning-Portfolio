# Nathan Lutes: Machine Learning Portfolio

This repository contains code from various projects I've completed during my internship at NASA Goddard Space Flight Center and during my PhD. The folders "CSNN_Braking_Intent_Detection" and "Few_Shot_Transfer_Learning" contain code I created for my two publications, "Convolutional Spiking Neural Networks for Intent Detection based on Anticipatory Brain Potentials using Electroencephalogram", published in Nature's Scientific Reports (https://www.nature.com/articles/s41598-024-59469-7), and "Few-Shot Transfer Learning for Individualized Braking Intent Detection on Neuromorphic Hardware" published in IOPScience's Journal of Neural Engineering (https://iopscience.iop.org/article/10.1088/1741-2552/adb079). "CSNN_Meta_Learning" contains code for a project that was not published and "NASA-Project" contains the code developed during my NASA internship.

The two publications also have their own git repositories:
Convolutional Spiking Neural Networks for Intent Detection based on Anticipatory Brain Potentials using Electroencephalogram - https://github.com/sid-nadendla/BI-SpikeEEG
Few-Shot Transfer Learning for Individualized Braking Intent Detection on Neuromorphic Hardware - https://github.com/sid-nadendla/TL-Akida

The "NASA-Project" directory contains code for building a machine learning model aimed at biotic pattern recognition inside of rocky substrate with the broader goal of advancing towards biotic life identification on foreign planets. The dataset (NASA proprietary, not included) consisted of a selection of images of various fossils and imprints on rocky substrates created by biotic life-forms combined with images of the same rocky substrates without biotic signatures such that the dataset provides an even number of positive and negative classes. The primary type of machine learning network used was a convolutional network implemented using transfer learning by fine-tuning an existing network. Throughout the project, a variety of computer vision approaches were attempted ranging from simple image classification to creation of boundary boxes around the biotic signatures to complete image segmentation. The toolset includes: a utilty for manual labeling of images created using python (SplitnClass_tool_GUI_OFF.py), a utility for creating a train/test split from the various image directories for interface with Keras (python), a python script utilzing transfer learning for image classification and a matlab file for using transfer learning for image segmentation. A final report drafted at the end of the internship is also included.

The "CSNN_Braking_Intent_Detection" directory contains code which explores the utility of implementing a relatively new form of neural network, the spiking neural network, for braking intent, or more general movement intent, detection through learning and interpolation of patterns emerging through electroencephalography (EEG) data. The code, written using python and pytorch, contains definitions for spiking neural networks using the "snntorch" library and the training of the networks is completed using pytorch. 10-fold cross-validation is used to draw superior statistical conclusions and to statistically compare the spiking neural network and other models such as EEGNet (implemented using tensorflow) and various graph neural networks (implemented using spektral). See the publication links for complete details. The code is organized with the primary training functions for each model being housed in the module named "Functions" and other utilities and commonly used tools being defined in the "tools" module. The top level "KFoldCrossValExp1.py" and "exp1_ablation_study.py" then operate by calling the appropriate training functions for each model. The code was developed with the intention of running on the local HPC cluster (which used Slurm as its scheduler).

 The "Few_Shot_Transfer_Learning" directory code expands on the ideas developed in the first paper to produce a few-shot transfer learning methodology that could be deployed on real hardware. The target hardware was the company Brainchip's "Akida" neuromorphic system on chip (NSoC) and as such much of the code revolves around compatibility with Brainchip's properietary API. The approach to the few-shot transfer learning was to first train an ordinary convolutional neural network on the CPU and then convert this CNN into a CSNN and map to the Akida chip using Brainchip's API. As the API is geared towards interfacing with tensorflow/keras, the continuous convolutonal models and the training/evaluation loops are created using this framework. The code is organized by controlling operation flow using the top level scripts "Exp1and2_Few_Shot_Transfer_Learning.py" and "Exp3_Few_Shot_Transfer_Learning.py" which call model definitions and training routines housed in the "models_exp#" and "tools_exp#" modules. The code is comprised of three steps: initial training of the continuous CPU, quantization and retraining of the continuous CPU and finally mapping the quantized CPU to the Akida chip and performing Akida edge-learning to fine-tune the model into a individualized model at the chip level. Complete details can be had in the paper at the reference above. The quantization and the on-chip learning are implemented using Brainchip's API. This code was also developed with the intention of running on the local HPC cluster.

The "CSNN_Meta_Learning" directory contains code for an unpublished project with a goal of achieving one-shot or few-shot learning using CSNNs on braking intent data using meta-learning. Similarly to the other directories, the code is organized via a single master script, in this case "meta_learning.py" which calls a series of other functions and tools which are housed in the accompanying modules. The approach is based largely off of the paper "One-shot learning with Spiking Neural Networks" by Franz Scherr et al and involves a dual loop approach for training both a teacher and learner network. Essentially, the teacher is trained on how to provide the best updates to the learner network and the learner network acts as a typical supervised learning scheme with the updates to the teacher being backpropagated through the errors made by the learner. More details can be found in the aforementioned paper and its dependencies. This approach was adapted to the braking intent detection problem using the datasets featured in the other directories. The implementation used in this project is based on tensorflow and features custom layer definitions as well as custom training routine definitions. This code was also run on a HPC cluster however, as mentioned before, the results of this project were not published.
